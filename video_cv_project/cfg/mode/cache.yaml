# @package _global_
# Config for cache mode.

defaults:
  - slot-base
  - override /data: kinetics400
  - override /data/transform: base
  - override /model: slot

mode: train

device: cpu

train:
  epochs: 1

  log_every: 999999999
  save_every: 999999999

  dryrun: true

  # TODO: Optimizer/scheduler can be its own sub-config.
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.0001

  scheduler:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    max_lr: ${..optimizer.lr}
    total_steps: ${total_steps}
    pct_start: 0.1

data:
  # cache_path: /home/jovyan/downloads/kinetics400-train.pt
  batch_size: 16
  num_workers: 16
  clips_per_vid: 40
  dataset:
    frames_per_clip: 1
    step_between_clips: 1
    # split: train

  transform:
    patch_func:
      # Done on CPU, cannot use too high batch size.
      device: cuda
      batch_size: 1
