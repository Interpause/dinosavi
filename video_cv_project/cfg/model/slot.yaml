# Config for SlotCPC model.

time_steps: 0
num_slots: 7
num_iters: 1
ini_iters: 1
_target_: video_cv_project.models.SlotCPC
model:
  _target_: video_cv_project.models.SlotModel
  add_pe: false
  slot_dim: 512 # 1024
  slot_hid_dim: 512 # 1024
  # Since these handle interactions between slots & predicts the next time step,
  # each head could theoretically handle a different aspect to update. For example,
  # changes in apperance, position, visibility, etc.
  slot_predict_heads: 4 # 8
  enc_cfg:
    _target_: transformers.ViTConfig.from_pretrained
    pretrained_model_name_or_path: ${vit_path}
decoder:
  _target_: video_cv_project.models.heads.AlphaSlotDecoder
  slot_dim: ${..model.slot_dim}
  # Should match dims of model.encoder's output feature map.
  # TODO: Can be auto-detected or read from model.encoder metadata, just no nice
  # way to pass to the decoder init.
  out_dim: 384
  depth: 2
  kernel_size: [3, 3]
  hid_dim: 512
  pe_type: linear
  # Decoder handles positional encoding interpolation.
  pe_size: [28, 28]
