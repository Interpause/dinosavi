# Config for SlotCPC model.

time_steps: 5
num_slots: 7
num_iters: 2
ini_iters: 3
_target_: video_cv_project.models.SlotCPC
model:
  _target_: video_cv_project.models.SlotModel
  add_pe: false
  slot_dim: 512
  slot_hid_dim: 512
  # Since these handle interactions between slots & predicts the next time step,
  # each head could theoretically handle a different aspect to update. For example,
  # changes in apperance, position, visibility, etc.
  slot_predict_heads: 4
  encoder:
    _target_: transformers.ViTModel.from_pretrained
    pretrained_model_name_or_path: /home/jovyan/workspaces/video-cv-project/pretrained/facebook/dino-vits8
    #pretrained_model_name_or_path: /home/jovyan/workspaces/video-cv-project/pretrained/facebook/vit-msn-small
    add_pooling_layer: false
decoder:
  _target_: video_cv_project.models.heads.AlphaSlotDecoder
  slot_dim: ${..model.slot_dim}
  # Should match dims of model.encoder's output feature map.
  # TODO: Can be auto-detected or read from model.encoder metadata, just no nice
  # way to pass to the decoder init.
  out_dim: 384
  depth: 1
  hid_dim: 512
  pe_type: linear
  # Decoder handles positional encoding interpolation.
  pe_size: [28, 28]
